# -*- coding: utf-8 -*-
import sqlite3
import pandas as pd
import json
from pathlib import Path


def upload_journal_metrics(
    disrupt_df: pd.DataFrame,
    interdisciplinary_df: pd.DataFrame,
    novelty_df: pd.DataFrame,
    topic_df: pd.DataFrame,
    theme_df: pd.DataFrame,
    year: int,
    db_config: dict = None,
    paper_count_df: pd.DataFrame = None,
    papers_df: pd.DataFrame = None,
):
    """
    ä¸Šä¼ æœŸåˆŠæŒ‡æ ‡åˆ° SQLite æ•°æ®åº“ï¼ˆå¢åŠ  top_keywordsã€paper_countã€category åˆ—ï¼‰

    å‚æ•°:
        disrupt_df: disruption ç»“æœ DataFrame, ['journal','percent_score']
        interdisciplinary_df: è·¨å­¦ç§‘æŒ‡æ ‡ DataFrame, ['journal','percent_score']
        novelty_df: æ–°é¢–æ€§æŒ‡æ ‡ DataFrame, ['journal','percent_score']
        topic_df: topic entropy æŒ‡æ ‡ DataFrame, ['journal','percent_score']
        theme_df: theme æŒ‡æ ‡ DataFrame, ['journal','theme_concentration','hot_response','top_keywords']
        year: int, æŒ‡æ ‡å¹´ä»½
        db_config: æ•°æ®åº“é…ç½®å­—å…¸, é»˜è®¤ä½¿ç”¨å†…ç½®é…ç½®
        paper_count_df: æœŸåˆŠè®ºæ–‡æ•° DataFrame, ['journal','paper_count']ï¼ˆå¯é€‰ï¼‰
        papers_df: è®ºæ–‡çº§æ•°æ® DataFrame, è‡³å°‘åŒ…å« ['journal','category']ï¼ˆå¯é€‰ï¼Œç”¨äºè®¡ç®— journal çš„ category ä¼—æ•°ï¼‰
    """

    if db_config is None:
        # é»˜è®¤ SQLite æ•°æ®åº“è·¯å¾„ï¼ˆç›¸å¯¹äºè„šæœ¬ç›®å½•ï¼‰
        db_config = {
            "dialect": "sqlite",
            "db_path": str(Path(__file__).resolve().parent.parent.parent.parent / "data" / "paper_system.db"),
        }

    # è·å–æ•°æ®åº“è·¯å¾„
    db_path = db_config.get("db_path", db_config.get("database", ""))
    print(f"ğŸ“Œ journal_metrics å†™å…¥ç›®æ ‡: SQLite {db_path}")

    # -------------------- åˆå¹¶å„æŒ‡æ ‡ --------------------
    dfs = [
        disrupt_df.rename(columns={"percent_score": "disruption"})[["journal", "disruption"]],
        interdisciplinary_df.rename(columns={"percent_score": "interdisciplinary"})[
            ["journal", "interdisciplinary"]
        ],
        novelty_df.rename(columns={"percent_score": "novelty"})[["journal", "novelty"]],
        topic_df.rename(columns={"percent_score": "topic"})[["journal", "topic"]],
        theme_df[[
            "journal", "theme_concentration", "hot_response",
            "top_keywords_2021", "top_keywords_2022", "top_keywords_2023", "top_keywords_2024", "top_keywords_2025"
        ]],
            ]

    if paper_count_df is not None and not paper_count_df.empty:
        cols = set(paper_count_df.columns)
        if "journal" in cols and "paper_count" in cols:
            dfs.append(paper_count_df[["journal", "paper_count"]])

    # è®¡ç®—æ¯ä¸ª journal çš„ä¸»å¯¼ categoryï¼ˆä¸¤ç±»æ—¶ï¼šæ•°é‡å¤šçš„ä¸€æ–¹ï¼›æ•°é‡ç›¸åŒåˆ™æŒ‰å­—æ¯åºæ›´å°çš„é‚£ä¸ªï¼‰
    if papers_df is not None and not papers_df.empty:
        cols = set(papers_df.columns)
        if "journal" in cols and "category" in cols:
            tmp = papers_df[["journal", "category"]].copy()
            tmp = tmp.dropna(subset=["journal", "category"])
            tmp["category"] = tmp["category"].astype(str).str.strip()
            tmp = tmp[tmp["category"] != ""]
            if not tmp.empty:
                counts = (
                    tmp.groupby(["journal", "category"])
                    .size()
                    .reset_index(name="cnt")
                    .sort_values(["journal", "cnt", "category"], ascending=[True, False, True])
                )
                journal_category_df = counts.drop_duplicates(subset=["journal"], keep="first")[
                    ["journal", "category"]
                ]
                dfs.append(journal_category_df)

    # å¤–è¿æ¥åˆå¹¶ï¼Œä¿è¯æ‰€æœ‰æœŸåˆŠéƒ½ä¿ç•™
    merged_df = dfs[0]
    for df in dfs[1:]:
        merged_df = pd.merge(merged_df, df, on="journal", how="outer")

    # æ·»åŠ å¹´ä»½åˆ—
    merged_df["year"] = year

    # paper_countï¼šè¡¨é‡Œæ˜¯ NOT NULLï¼Œç¼ºå¤±æ—¶è¡¥ 0
    if "paper_count" not in merged_df.columns:
        merged_df["paper_count"] = 0
    merged_df["paper_count"] = merged_df["paper_count"].fillna(0).astype(int)

    # -------------------- å†™å…¥æ•°æ®åº“ --------------------
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()

    # SQLite ä½¿ç”¨ INSERT OR REPLACE è€Œä¸æ˜¯ ON DUPLICATE KEY UPDATE
    insert_sql = """
        INSERT OR REPLACE INTO journal_metrics
            (journal, year, disruption, interdisciplinary, novelty, topic,
            theme_concentration, hot_response,
            top_keywords_2021, top_keywords_2022, top_keywords_2023, top_keywords_2024, top_keywords_2025,
            paper_count, category)
        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        """

    for _, row in merged_df.iterrows():
        def _kw_to_json(v):
            if isinstance(v, float) and pd.isna(v):
                v = []
            if v is None:
                v = []
            # å…¼å®¹å¼‚å¸¸è¾“å…¥ï¼šå­—ç¬¦ä¸²å½¢å¼çš„ list / JSON
            if isinstance(v, str):
                s = v.strip()
                if not s or s.lower() in {"nan", "none", "null"}:
                    v = []
                else:
                    parsed = None
                    try:
                        parsed = json.loads(s)
                    except Exception:
                        parsed = None
                    if parsed is None and s.startswith("[") and s.endswith("]"):
                        try:
                            import ast

                            parsed = ast.literal_eval(s)
                        except Exception:
                            parsed = None
                    if isinstance(parsed, list):
                        v = parsed
                    elif isinstance(parsed, (tuple, set)):
                        v = list(parsed)
                    elif isinstance(parsed, str):
                        # æç«¯æƒ…å†µï¼šJSON é‡ŒåŒ…äº†ä¸€å±‚å­—ç¬¦ä¸²
                        inner = parsed.strip()
                        if inner == "[]":
                            v = []
            return json.dumps(v, ensure_ascii=False)

        kw_2021 = _kw_to_json(row.get("top_keywords_2021"))
        kw_2022 = _kw_to_json(row.get("top_keywords_2022"))
        kw_2023 = _kw_to_json(row.get("top_keywords_2023"))
        kw_2024 = _kw_to_json(row.get("top_keywords_2024"))
        kw_2025 = _kw_to_json(row.get("top_keywords_2025"))

        params = [
            row.get("journal"),
            row.get("year"),
            row.get("disruption"),
            row.get("interdisciplinary"),
            row.get("novelty"),
            row.get("topic"),
            row.get("theme_concentration"),
            row.get("hot_response"),
            kw_2021, kw_2022, kw_2023, kw_2024, kw_2025,
            int(row.get("paper_count", 0)) if not pd.isna(row.get("paper_count", 0)) else 0,
            row.get("category"),
        ]

        # å°† pandas çš„ NaN è½¬æ¢ä¸º Noneï¼ˆpaper_count å·²ä¿è¯ä¸º int ä¸ä¸ºç©ºï¼‰
        clean_params = [None if pd.isna(x) else x for x in params]
        cursor.execute(insert_sql, tuple(clean_params))

    conn.commit()
    cursor.close()
    conn.close()

    print(f"âœ… æˆåŠŸä¸Šä¼  {len(merged_df)} æ¡æœŸåˆŠæŒ‡æ ‡æ•°æ®åˆ° journal_metrics è¡¨")